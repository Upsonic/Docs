---
title: OllamaProvider
sidebarTitle: OllamaProvider
---

## Parameters

| Parameter                          | Type                                                  | Default    | Description                                                                                                                                                                                                                      |
| ---------------------------------- | ----------------------------------------------------- | ---------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `base_url`                         | `str \| None`                                         | `None`     | The base url for the Ollama requests. If not provided, the `OLLAMA_BASE_URL` environment variable will be used if available.                                                                                                    |
| `api_key`                          | `str \| None`                                         | `None`     | The API key to use for authentication, if not provided, the `OLLAMA_API_KEY` environment variable will be used if available.                                                                                                 |
| `openai_client`                   | `AsyncOpenAI \| None`                                 | `None`     | An existing [`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage) client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.                                        |
| `http_client`                      | `httpx.AsyncClient \| None`                           | `None`     | An existing `httpx.AsyncClient` to use for making HTTP requests.                                                                                                                                                                 |

## Functions

### `__init__`

Create a new Ollama provider.

**Parameters:**

- `base_url` (str | None): The base url for the Ollama requests. If not provided, the `OLLAMA_BASE_URL` environment variable will be used if available.
- `api_key` (str | None): The API key to use for authentication, if not provided, the `OLLAMA_API_KEY` environment variable will be used if available.
- `openai_client` (AsyncOpenAI | None): An existing [`AsyncOpenAI`](https://github.com/openai/openai-python?tab=readme-ov-file#async-usage) client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.
- `http_client` (httpx.AsyncClient | None): An existing `httpx.AsyncClient` to use for making HTTP requests.

### `name`

Get the provider name.

**Returns:**

- `str`: The provider name ('ollama')

### `base_url`

Get the base URL for the provider API.

**Returns:**

- `str`: The base URL for the provider API

### `client`

Get the client for the provider.

**Returns:**

- `AsyncOpenAI`: The Ollama client

### `model_profile`

Get the model profile for the named model, if available.

**Parameters:**

- `model_name` (str): The name of the model

**Returns:**

- `ModelProfile | None`: The model profile for the named model, if available
