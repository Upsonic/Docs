---
title: "Overview"
description: "Content safety and policy enforcement for AI agents"
---

## What is Safety Engine?

Safety Engine is a comprehensive content filtering and policy enforcement system for AI agents. It allows you to control what goes into your agents (user input) and what comes out (agent responses) by applying policies that automatically detect and handle sensitive content like PII, prohibited topics, adult content, hate speech, or custom safety rules.

## How Safety Engine Works

Safety Engine operates at two key points in your agent's lifecycle:

1. **Before Processing (user_policy)**: Filters and validates user input before it reaches your agent
2. **After Processing (agent_policy)**: Sanitizes and validates agent output before it's returned to the user

Each policy consists of two components:
- **Rule**: Detects specific content (e.g., "Does this text contain credit card numbers?")
- **Action**: Decides what to do when content is detected (e.g., "Block it", "Anonymize it", "Replace it")

## Why Safety Engine is Important

- **Compliance**: Meet regulatory requirements (GDPR, HIPAA, PCI-DSS, etc.)
- **Privacy Protection**: Automatically detect and protect sensitive personal information
- **Content Moderation**: Block inappropriate, harmful, or prohibited content
- **Risk Mitigation**: Prevent your AI from exposing sensitive data or violating policies
- **Multi-language Support**: Automatically adapts to user's language
- **Flexibility**: Use pre-built policies or create custom ones for your specific needs
