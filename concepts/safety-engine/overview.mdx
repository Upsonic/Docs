---
title: "Safety Engine"
description: "Content safety and policy enforcement for AI agents"
sidebarTitle: Overview
hideToc: true
---


## Overview

Safety Engine provides content filtering and policy enforcement for AI agents. It controls what goes into agents (user input) and what comes out (agent responses) by applying policies that detect and handle sensitive content.

## Key Features

- **Input/Output Filtering**: Validate user input and agent responses
- **Pre-built Policies**: Ready-to-use policies for PII, adult content, hate speech, etc.
- **Custom Policies**: Create your own rules and actions
- **Multiple Actions**: Block, anonymize, replace, or raise exceptions
- **Multi-language Support**: Automatically adapts to user's language
- **LLM-Powered Detection**: Use LLMs for context-aware content detection

## Example

```python
from upsonic import Agent, Task
from upsonic.safety_engine.policies.pii_policies import PIIAnonymizePolicy

# Create agent with PII anonymization
agent = Agent(
    "openai/gpt-4o",
    agent_policy=PIIAnonymizePolicy
)

# User input with PII
task = Task(
    description="My email is john.doe@example.com and phone is 555-1234. What are my email and phone?"
)

# Execute - PII will be anonymized in output
result = agent.do(task)
print(result)  # PII like email and phone will be anonymized
```
