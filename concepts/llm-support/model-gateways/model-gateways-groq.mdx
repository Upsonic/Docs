---
title: "Groq"
description: "Using Groq for ultra-fast LLM inference with Upsonic"
---

## Overview

Groq provides ultra-fast inference through their Language Processing Unit (LPU) technology. Access open-source models with industry-leading speed and built-in web search capabilities.

**Model Class:** `GroqModel`

## Authentication

```bash
export GROQ_API_KEY="gsk_..."
```

## Examples

```python
from upsonic import Agent, Task
from upsonic.models.groq import GroqModel

model = GroqModel(model_name="llama-3.3-70b-versatile")
agent = Agent(model=model)

task = Task("Hello, how are you?")
result = agent.do(task)
print(result.output)
```

## Parameters

| Parameter | Type | Description | Default | Source |
|-----------|------|-------------|---------|--------|
| `max_tokens` | `int` | Maximum tokens to generate | 1024 | Base |
| `temperature` | `float` | Sampling temperature (0.0-2.0) | 1.0 | Base |
| `top_p` | `float` | Nucleus sampling | 1.0 | Base |
| `seed` | `int` | Random seed | None | Base |
| `stop_sequences` | `list[str]` | Stop sequences | None | Base |
| `presence_penalty` | `float` | Token presence penalty | 0.0 | Base |
| `frequency_penalty` | `float` | Token frequency penalty | 0.0 | Base |
| `parallel_tool_calls` | `bool` | Allow parallel tools | True | Base |
| `timeout` | `float` | Request timeout (seconds) | 600 | Base |
| `groq_reasoning_format` | `'hidden' \| 'raw' \| 'parsed'` | Reasoning output format | None | Specific |
