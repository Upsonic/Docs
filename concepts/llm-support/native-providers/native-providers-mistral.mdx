---
title: "Mistral"
description: "Using Mistral AI models with Upsonic"
---

## Overview

Mistral AI provides high-performance open and commercial models including Mistral Large and Codestral. Known for strong performance and European values.

**Model Class:** `MistralModel`

## Authentication

```bash
export MISTRAL_API_KEY="..."
```

## Examples

```python
from upsonic import Agent, Task
from upsonic.models.mistral import MistralModel

model = MistralModel(model_name="mistral-large-latest")
agent = Agent(model=model)

task = Task("Hello, how are you?")
result = agent.do(task)
print(result)
```

## Model Settings

You can set model parameters in two ways: on the model or on the Agent.

**On the model:**

```python
from upsonic import Agent, Task
from upsonic.models.mistral import MistralModel, MistralModelSettings

model = MistralModel(
    model_name="mistral-large-latest",
    settings=MistralModelSettings(max_tokens=1024, temperature=0.7)
)
agent = Agent(model=model)
```

**On the Agent:**

```python
from upsonic import Agent, Task
from upsonic.models.mistral import MistralModelSettings

agent = Agent(
    model="mistral/mistral-large-latest",
    settings=MistralModelSettings(max_tokens=1024)
)
```

## Parameters

| Parameter | Type | Description | Default | Source |
|-----------|------|-------------|---------|--------|
| `max_tokens` | `int` | Maximum tokens to generate | Model default | Base |
| `temperature` | `float` | Sampling temperature (0.0-1.0) | 0.7 | Base |
| `top_p` | `float` | Nucleus sampling | 1.0 | Base |
| `seed` | `int` | Random seed | None | Base |
| `stop_sequences` | `list[str]` | Stop generation sequences | None | Base |
| `presence_penalty` | `float` | Token presence penalty | 0.0 | Base |
| `frequency_penalty` | `float` | Token frequency penalty | 0.0 | Base |
| `timeout` | `float` | Request timeout (seconds) | 600 | Base |
