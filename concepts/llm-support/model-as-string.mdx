---
title: "Model as String"
description: "Using string-based model identifiers for simplified configuration"
---

## What is Model as String?

**It's useful** - Instead of importing and instantiating model classes, you can simply use a string identifier to specify which model you want to use. This makes it incredibly easy to switch between models, configure models via environment variables, or dynamically select models at runtime.

With Model as String, you can skip the boilerplate code and get straight to building. Just specify the provider and model ID in a simple string format, and Upsonic handles the rest.

## Format

The string format follows this pattern:

```
"provider/model_id"
```

- **provider**: The model provider name (case-insensitive)
- **model_id**: The specific model identifier

**Examples:**
- `"openai/gpt-4o"`
- `"anthropic/claude-sonnet-4-20250514"`
- `"google/gemini-2.0-flash-exp"`
- `"groq/llama-3.3-70b-versatile"`
- `"deepseek/deepseek-chat"`
- `"ollama/llama3.2"`

## Examples

### Basic Usage with Agent

```python
from upsonic import Agent, Task

# Simply use a string instead of a model class
agent = Agent(model="anthropic/claude-sonnet-4-5")

task = Task("Hello, how are you?")
result = agent.do(task)
print(result)
```

### Switching Models Easily

```python
from upsonic import Agent, Task

# Try different models without changing imports
models = [
    "openai/gpt-4o",
    "anthropic/claude-3-5-sonnet-20241022",
    "google/gemini-2.5-flash",
    "groq/llama-3.3-70b-versatile"
]

for model_string in models:
    agent = Agent(model=model_string)
    result = agent.do(Task("What is AI?"))
    print(f"{model_string}: {result[:100]}...")
```

### Environment-Based Configuration

```python
import os
from upsonic import Agent, Task

# Configure via environment variable
model_string = os.getenv("LLM_MODEL_KEY", "anthropic/claude-sonnet-4-5")

agent = Agent(model=model_string)
task = Task("Analyze this data")
result = agent.do(task)
```

**.env file:**
```bash
# Switch models without code changes
LLM_MODEL_KEY=anthropic/claude-3-5-sonnet-20241022

# Or use a different provider
LLM_MODEL_KEY=groq/llama-3.3-70b-versatile
```

### Dynamic Model Selection

```python
from upsonic import Agent, Task

def get_model_for_task(task_type: str) -> str:
    """Select the best model for each task type."""
    if task_type == "code":
        return "anthropic/claude-3-5-sonnet-20241022"
    elif task_type == "reasoning":
        return "openai/o1-preview"
    elif task_type == "fast":
        return "groq/llama-3.3-70b-versatile"
    else:
        return "openai/gpt-4o"

# Use different models for different tasks
code_agent = Agent(model=get_model_for_task("code"))
reasoning_agent = Agent(model=get_model_for_task("reasoning"))
fast_agent = Agent(model=get_model_for_task("fast"))
```

<Info>
**Universal Usage**: Model as String can be used anywhere you would normally use a Model class instance - in Agents, Teams, Direct LLM Calls, and more. It's a drop-in replacement that works everywhere.
</Info>

## Made with Love ðŸ’š

At Upsonic, we're always thinking about developers. We know that simplicity and developer experience matter just as much as features and performance.

Model as String is one of the many ways we try to make your life easier. No more boilerplate imports, no more complex configurations - just a simple string and you're ready to go. Because we believe that the best tools are the ones that get out of your way and let you focus on building amazing things.

We build Upsonic with love, for developers who love to build.
