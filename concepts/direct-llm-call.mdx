---
description: "High-speed, streamlined interface for direct LLM interactions without memory or tool complexity"
---

## Overview

### What is Direct LLM Call?

`Direct` is a simplified, high-speed interface for LLM interactions in the Upsonic AI Agent Framework. It provides a streamlined way to communicate with language models without the overhead of memory management, knowledge bases, or tool orchestration. This component is designed for scenarios where you need fast, direct responses from an LLM with minimal configuration.

### How Direct LLM Call Works

The Direct LLM Call mechanism operates through a straightforward pipeline:

1. **Initialization**: Create a `Direct` instance with your preferred model and optional configuration (settings, profile, provider)
2. **Task Definition**: Define your task using the `Task` object, which includes the description, optional attachments, context, and response format
3. **Execution**: Execute the task using `do()` for synchronous or `do_async()` for asynchronous operations
4. **Response Processing**: The system automatically processes the LLM response based on your specified response format (string or Pydantic model)

The Direct class handles all the underlying complexity including:
- Model instantiation and configuration
- Message construction from task descriptions and attachments
- Request parameter building based on response format requirements
- Automatic parsing of structured outputs
- Usage metrics tracking

### Why We Need Direct LLM Call

Direct LLM Call addresses specific needs in AI agent development:

- **Performance**: Eliminates overhead from memory, context management, and tool orchestration when these features are unnecessary
- **Simplicity**: Provides a clean API for straightforward LLM interactions without learning complex agent patterns
- **Structured Outputs**: Built-in support for Pydantic models ensures type-safe, validated responses
- **Flexibility**: Fluent interface allows easy configuration switching (different models, settings, profiles)
- **Document Processing**: Native support for attachments (PDFs, images) with automatic MIME type detection
- **Async Support**: Full async/await support for high-concurrency scenarios

## Attributes

The `Direct` class accepts the following attributes during initialization:

| Attribute | Type | Description | Default |
|-----------|------|-------------|---------|
| **model** | `Union[str, Any, None]` | Model identifier (e.g., "openai/gpt-4o"), Model instance, or None | `"openai/gpt-4o"` (when None) |
| **settings** | `Optional[ModelSettings]` | Model-specific configuration including temperature, max_tokens, etc. | `None` |
| **profile** | `Optional[ModelProfileSpec]` | Model profile configuration for advanced customization | `None` |
| **provider** | `Optional[Union[str, Provider]]` | Provider name or Provider instance for custom provider integration | `None` |

### Fluent Interface Methods

The Direct class provides immutable configuration methods that return new instances:

- `with_model(model)`: Create new instance with specified model
- `with_settings(settings)`: Create new instance with specified settings
- `with_profile(profile)`: Create new instance with specified profile
- `with_provider(provider)`: Create new instance with specified provider

### Execution Methods

- `do(task, show_output=True)`: Execute task synchronously
- `do_async(task, show_output=True)`: Execute task asynchronously
- `print_do(task)`: Execute task synchronously with visual output
- `print_do_async(task)`: Execute task asynchronously with visual output

## Example

### Basic Direct LLM Call Example

#### About Example Scenario

This example demonstrates a practical use case for Direct LLM Call: extracting structured information from a business document. We have a PDF invoice and need to extract key financial information in a type-safe, validated format. This scenario showcases:

- Document processing with attachments
- Structured output using Pydantic models
- Simple, direct execution without agent complexity
- Type-safe data extraction

#### Direct LLM Call Configuration

**Model Selection**: We use `"openai/gpt-4o"` for its strong vision and reasoning capabilities, essential for document understanding.

**Task Configuration**:
- **Description**: Clear instruction for the LLM
- **Attachments**: PDF document passed as attachment for processing
- **Response Format**: Pydantic model (`InvoiceData`) ensures validated, structured output with required fields

**Pydantic Model**: Defines the expected structure with field types, ensuring runtime validation and type safety. The model includes:
- Invoice number (string)
- Total amount (float)
- Issue date (string)
- List of line items with name and amount

#### Full Code

```python
from upsonic import Direct, Task
from pydantic import BaseModel


# Define the structured response format
class LineItem(BaseModel):
    name: str
    amount: float


class InvoiceData(BaseModel):
    invoice_number: str
    total_amount: float
    issue_date: str
    line_items: list[LineItem]


# Initialize Direct with GPT-4o
direct = Direct(model="openai/gpt-4o")

# Create task with document attachment and structured response
task = Task(
    description="Extract invoice data from this document including invoice number, total amount, issue date, and all line items with their amounts.",
    attachments=["invoice.pdf"],
    response_format=InvoiceData
)

# Execute and get structured result
result = direct.do(task)

# Access structured data with type safety
print(f"Invoice: {result.invoice_number}")
print(f"Total: ${result.total_amount}")
print(f"Date: {result.issue_date}")
print(f"\nLine Items:")
for item in result.line_items:
    print(f"  - {item.name}: ${item.amount}")
```

**Expected Output Structure**:
```
Invoice: INV-2024-001
Total: $1250.50
Date: 2024-10-29

Line Items:
  - Consulting Services: $1000.00
  - Software License: $250.50
```

**Key Features Demonstrated**:
- Automatic PDF processing through attachments
- Type-safe structured output with Pydantic validation
- Clean, synchronous API for straightforward use cases
- Zero configuration for memory or tools
- Automatic MIME type detection for attachments

## Image Processing

The Direct class can process image URLs and download images for fast, simple operations without tool overhead.

### Extracting Images from URLs

```python
from upsonic import Direct, Task
from upsonic.utils.image import extract_and_save_images_from_response

# Create Direct instance
direct = Direct(model="openai/gpt-4o")

# Get response with image URLs
task = Task(
    description=(
        "Provide a markdown formatted image. "
        "Format as: ![Image](https://example.com/image.jpg)"
    )
)
result = direct.do(task)

# Extract and save images from response (folder created automatically)
saved_images = extract_and_save_images_from_response(
    response_text=result,
    folder_path="downloaded_images",
    base_filename="downloaded"
)

print(f"Saved {len(saved_images)} images")
```

### Saving Base64 Images

```python
from upsonic.utils.image import save_image_to_folder

# Save base64 encoded image
base64_string = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAAB..."

saved_path = save_image_to_folder(
    image_data=base64_string,
    folder_path="my_images",
    filename="decoded.png",
    is_base64=True
)
```

### Saving Raw Image Bytes

```python
from upsonic.utils.image import save_image_to_folder

# Save raw image bytes
image_bytes = b'\x89PNG\r\n...'

saved_path = save_image_to_folder(
    image_data=image_bytes,
    folder_path="my_images",
    filename="raw_image.png",
    is_base64=False
)
```

### Batch Processing URLs

```python
from upsonic.utils.image import extract_image_urls, urls_to_base64, save_image_to_folder

# Extract URLs from text
text = "Check out ![Image1](https://example.com/1.jpg) and ![Image2](https://example.com/2.jpg)"
urls = extract_image_urls(text)

# Download all as base64
base64_images = urls_to_base64(urls)

# Save all images
for i, b64_img in enumerate(base64_images, 1):
    save_image_to_folder(
        image_data=b64_img,
        folder_path="downloaded",
        filename=f"image_{i}.png",
        is_base64=True
    )
```

### Managing Image Folders

```python
from upsonic.utils.image import list_images_in_folder, open_images_from_folder

# List all images (newest first)
images = list_images_in_folder("my_images")

# Open all images (limit to 5)
opened = open_images_from_folder("my_images", limit=5)

print(f"Opened {len(opened)} images")
```
