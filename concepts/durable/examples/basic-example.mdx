---
title: "Basic Example"
description: "Complete workflow with durable execution, failure handling, and recovery"
---

## About Example Scenario

This example demonstrates a complete workflow with durable execution, including task creation, execution with automatic checkpointing, failure handling, and recovery.

## Durable Execution Configuration

```python
from upsonic import Agent, Task
from upsonic.durable import DurableExecution, FileDurableStorage
from upsonic.tools import tool

# Create storage
storage = FileDurableStorage("./checkpoints")

# Create durable execution
durable = DurableExecution(
    storage=storage,
    auto_cleanup=False,  # Keep records for inspection
    debug=True           # Enable debug logging
)
```

## Full Code

```python
import asyncio
from upsonic import Agent, Task
from upsonic.durable import DurableExecution, FileDurableStorage
from upsonic.tools import tool

# Define tools for the task
@tool
def verify_tool(data_source: str) -> bool:
    """Verify data source is accessible."""
    print(f"Verifying {data_source}...")
    return True

@tool
def process_tool(record_count: int) -> dict:
    """Process specified number of records."""
    print(f"Processing {record_count} records...")
    return {"processed": record_count, "status": "success"}

@tool
def report_tool(data: str) -> str:
    """Generate final report."""
    print(f"Generating report from {data} records...")
    return f"Report generated for {data} records"


async def main():
    print("="*60)
    print("DURABLE EXECUTION EXAMPLE")
    print("="*60)

    # Create storage
    storage = FileDurableStorage("./checkpoints")

    # Create durable execution
    durable = DurableExecution(
        storage=storage,
        auto_cleanup=False,
        debug=True
    )

    # Create agent and task
    agent = Agent("openai/gpt-4o")
    task = Task(
        description="Complete data processing workflow: "
        "1. Verify data source 'database.csv' is accessible "
        "2. Process 1000 records "
        "3. Generate final report",
        tools=[verify_tool, process_tool, report_tool],
        durable_execution=durable
    )

    execution_id = task.durable_execution_id
    print(f"\nüÜî Execution ID: {execution_id}")
    print(f"üìÅ Checkpoint storage: ./checkpoints/")

    # Execute with automatic checkpointing
    print("\n" + "="*60)
    print("PHASE 1: INITIAL EXECUTION")
    print("="*60)

    try:
        result = agent.do(task)
        print(f"\n‚úÖ Execution completed successfully!")
        print(f"Result: {result}")

    except Exception as e:
        print(f"\n‚ùå Execution failed: {e}")

        # Get execution details
        print("\n" + "="*60)
        print("CHECKPOINT INSPECTION")
        print("="*60)

        exec_info = durable.get_execution_info()

        if exec_info:
            print(f"Status: {exec_info['status']}")
            print(f"Failed at step: {exec_info['step_index']} ({exec_info['step_name']})")
            print(f"Error: {exec_info.get('error', 'N/A')}")
            print(f"Timestamp: {exec_info['timestamp']}")

        # Attempt recovery
        print("\n" + "="*60)
        print("PHASE 2: RECOVERY")
        print("="*60)

        print("\nüîÑ Attempting recovery...")

        try:
            # Resume from checkpoint
            result = agent.continue_durable(
                durable_execution_id=execution_id,
                storage=storage
            )

            print(f"\n‚úÖ Recovery successful!")
            print(f"Result: {result}")

        except Exception as recovery_error:
            print(f"\n‚ùå Recovery failed: {recovery_error}")
            raise

    # Display analytics
    print("\n" + "="*60)
    print("EXECUTION ANALYTICS")
    print("="*60)

    stats = storage.get_stats()
    print(f"Backend: {stats['backend']}")
    print(f"Total executions: {stats['total_executions']}")
    print(f"By status: {stats['by_status']}")

    # List all executions
    all_executions = await DurableExecution.list_all_executions_async(storage)
    print(f"\nAll executions in storage: {len(all_executions)}")

    for exec_data in all_executions[:5]:
        print(f"  ‚Ä¢ {exec_data['execution_id'][:30]}...")
        print(f"    Status: {exec_data['status']}")
        print(f"    Step: {exec_data['step_name']}")

    # Cleanup
    print("\n" + "="*60)
    print("CLEANUP")
    print("="*60)

    deleted = await storage.cleanup_old_executions_async(older_than_days=30)
    print(f"Cleaned up {deleted} old executions")

    print("\n‚úÖ Example completed!")

if __name__ == "__main__":
    asyncio.run(main())
```

This example demonstrates:
- ‚úÖ Creating durable execution with file storage
- ‚úÖ Task execution with automatic checkpointing
- ‚úÖ Failure detection and checkpoint inspection
- ‚úÖ Recovery from the point of failure
- ‚úÖ Execution analytics and statistics
- ‚úÖ Cleanup operations
