---
title: "Model Provider Tools"
description: "Native tools provided by AI model providers"
---

## Overview

Model provider tools are native capabilities provided directly by AI model providers (OpenAI, Anthropic, Google). These tools are executed by the provider's infrastructure rather than the Upsonic framework, offering provider-optimized performance and specialized features.

### Key Characteristics

- **Provider-Executed**: Run on model provider infrastructure, not in your code
- **Native Integration**: Deep integration with model capabilities
- **Specialized Features**: Provider-specific optimizations and configurations
- **Automatic Rate Limiting**: Provider-managed execution and rate limiting
- **Sequential Execution**: Always executed sequentially by the provider

### Differences from Custom Tools

| Feature | Custom Tools | Model Provider Tools |
|---------|--------------|---------------------|
| **Execution** | Upsonic Framework | Provider Infrastructure |
| **Configuration** | Full Support | Provider-Specific Only |
| **Parallelization** | ✅ Supported | ❌ Always Sequential |
| **Caching** | ✅ Configurable | ❌ Provider-Managed |
| **Retries** | ✅ Configurable | ❌ Provider-Managed |
| **Hooks** | ✅ Supported | ❌ Not Supported |

## Supported Providers

Model provider tools are supported by specific AI providers:

### Provider Compatibility

| Tool | OpenAI Responses | Anthropic | Google | Azure OpenAI |
|------|------------------|-----------|--------|--------------|
| **WebSearchTool** | ✅ | ✅ | ✅ | ❌ |
| **CodeExecutionTool** | ✅ | ✅ | ✅ | ❌ |
| **UrlContextTool** | ❌ | ❌ | ✅ | ❌ |

### Important Notes

**For OpenAI:**
- ✅ Use `openai-responses/gpt-4o` for model provider tools
- ❌ Do NOT use `openai/gpt-4o` (standard chat completion model)

**For Azure OpenAI:**
- ❌ Model provider tools are NOT supported
- ✅ Use custom tools instead with `azure/gpt-4o`

**For Anthropic:**
- ✅ Full support for WebSearchTool and CodeExecutionTool

**For Google:**
- ✅ Full support including exclusive UrlContextTool

## Tools

### WebSearchTool

A built-in tool that allows models to search the web for information.

**Usage:**

```python
from upsonic import Agent, Task
from upsonic.tools.builtin_tools import WebSearchTool
from upsonic.models.openai import OpenAIResponsesModel

# Create model with OpenAI Responses API
model = OpenAIResponsesModel(
    model_name="gpt-4o",
    provider="openai"
)

# Basic web search tool
web_search = WebSearchTool()

# Create task
task = Task(
    description="Search for latest AI news and summarize the findings",
    tools=[web_search]
)

# Create agent
agent = Agent(model=model, name="Web Search Agent")

# Execute
result = agent.do(task)
print(f"Result: {result}")
```

**Advanced Configuration:**

```python
from upsonic.tools.builtin_tools import WebSearchTool, WebSearchUserLocation

# Advanced web search with configuration
advanced_search = WebSearchTool(
    search_context_size="high",  # 'low', 'medium', or 'high'
    user_location=WebSearchUserLocation(
        city="San Francisco",
        country="US",
        region="CA",
        timezone="America/Los_Angeles"
    ),
    blocked_domains=["example.com", "spam-site.com"],
    max_uses=10
)

task = Task(
    description="Search for AI trends with high context and location filtering",
    tools=[advanced_search]
)

agent = Agent(model=model, name="Advanced Search Agent")
agent.print_do(task)
```

**Parameters:**

- `search_context_size` (str): Context amount - 'low', 'medium', or 'high' (default: 'medium')
  - Supported by: OpenAI Responses
- `user_location` (WebSearchUserLocation, optional): Localize search results
  - Supported by: Anthropic, OpenAI Responses
- `blocked_domains` (List[str], optional): Domains to exclude from results
  - Supported by: Anthropic, Groq
- `allowed_domains` (List[str], optional): Only include these domains
  - Supported by: Anthropic, Groq
  - Note: Cannot use both blocked_domains and allowed_domains with Anthropic
- `max_uses` (int, optional): Maximum number of searches allowed
  - Supported by: Anthropic

### WebSearchUserLocation

User location information for localizing web search results.

**Usage:**

```python
from upsonic.tools.builtin_tools import WebSearchTool, WebSearchUserLocation

# Create location configuration
user_location = WebSearchUserLocation(
    city="New York",
    country="US",
    region="NY",
    timezone="America/New_York"
)

# Apply to web search
web_search = WebSearchTool(user_location=user_location)

task = Task(
    description="Search for local news and events",
    tools=[web_search]
)

agent = Agent(model=model, name="Local Search Agent")
agent.print_do(task)
```

**Parameters:**

- `city` (str): The city where the user is located
- `country` (str): Country code (e.g., 'US', 'GB', 'DE')
  - For OpenAI: Must be 2-letter country code
- `region` (str): Region or state code (e.g., 'CA', 'NY', 'TX')
- `timezone` (str): Timezone identifier (e.g., 'America/New_York')

**Provider Support:**
- Anthropic: ✅ Full support
- OpenAI Responses: ✅ Full support

### CodeExecutionTool

A built-in tool that allows models to execute code in a sandboxed environment.

**Usage:**

```python
from upsonic import Agent, Task
from upsonic.tools.builtin_tools import CodeExecutionTool
from upsonic.models.openai import OpenAIResponsesModel

# Create model
model = OpenAIResponsesModel(
    model_name="gpt-4o",
    provider="openai"
)

# Create code execution tool
code_exec = CodeExecutionTool()

# Create task
task = Task(
    description="Write a Python function to calculate factorial and test it with 5",
    tools=[code_exec]
)

# Create agent
agent = Agent(model=model, name="Code Execution Agent")

# Execute
result = agent.do(task)
print(f"Result: {result}")
```

**Advanced Example:**

```python
from upsonic.tools.builtin_tools import CodeExecutionTool

code_exec = CodeExecutionTool()

# Complex computation task
task = Task(
    description="""
    Write and execute Python code to:
    1. Calculate Fibonacci sequence up to 10 terms
    2. Find prime numbers up to 50
    3. Create a simple data visualization (if matplotlib available)
    """,
    tools=[code_exec]
)

agent = Agent(model=model, name="Computational Agent")
agent.print_do(task)
```

**Parameters:**

- No configuration parameters (provider-managed execution)

**Provider Support:**
- Anthropic: ✅ Full support
- OpenAI Responses: ✅ Full support
- Google: ✅ Full support

**Characteristics:**
- Sandboxed execution environment
- Python code support
- Provider-managed security and isolation
- Automatic timeout and resource limits

### UrlContextTool

Allows models to access and read contents from URLs directly.

**Usage:**

```python
from upsonic import Agent, Task
from upsonic.tools.builtin_tools import UrlContextTool

# Create URL context tool
url_tool = UrlContextTool()

# Create task
task = Task(
    description="Read content from https://docs.python.org and explain Python basics",
    tools=[url_tool]
)

# Create agent with Google model (required for UrlContextTool)
agent = Agent(
    model="google/gemini-1.5-pro",
    name="URL Context Agent"
)

# Execute
agent.print_do(task)
```

**Advanced Example:**

```python
from upsonic.tools.builtin_tools import UrlContextTool

url_tool = UrlContextTool()

# Multiple URL access task
task = Task(
    description="""
    Access and analyze these documentation pages:
    1. https://docs.python.org
    2. https://www.python.org/dev/peps/
    
    Provide a summary of Python's key features and recent PEPs
    """,
    tools=[url_tool]
)

agent = Agent(model="google/gemini-1.5-pro", name="Multi-URL Agent")
agent.print_do(task)
```

**Parameters:**

- No configuration parameters (provider-managed)

**Provider Support:**
- Google: ✅ Exclusive support
- Other providers: ❌ Not supported

**Characteristics:**
- Direct URL content access
- Provider-managed fetching and parsing
- Automatic handling of different content types
- Built-in security and validation

## Combining Model Provider Tools

Combine multiple model provider tools for comprehensive capabilities:

```python
from upsonic import Agent, Task
from upsonic.tools.builtin_tools import WebSearchTool, CodeExecutionTool
from upsonic.models.openai import OpenAIResponsesModel

# Create model
model = OpenAIResponsesModel(
    model_name="gpt-4o",
    provider="openai"
)

# Create multiple tools
web_search = WebSearchTool(search_context_size='high')
code_exec = CodeExecutionTool()

# Create task combining both
task = Task(
    description="""
    1. Search for current Python best practices
    2. Write example code demonstrating these practices
    3. Execute the code to verify it works
    """,
    tools=[web_search, code_exec]
)

# Create agent
agent = Agent(model=model, name="Research & Code Agent")

# Execute
result = agent.do(task)
print(f"Result: {result}")
```

## Best Practices

### Choosing the Right Model

1. **For WebSearchTool and CodeExecutionTool:**
   - ✅ Use `openai-responses/gpt-4o` (not `openai/gpt-4o`)
   - ✅ Use Anthropic models
   - ✅ Use Google models

2. **For UrlContextTool:**
   - ✅ Use Google models only
   - ❌ Not available on other providers

3. **For Azure OpenAI:**
   - ❌ Model provider tools not supported
   - ✅ Use custom tools instead

### Configuration Tips

1. **WebSearchTool:**
   - Use `search_context_size='high'` for detailed research
   - Set `max_uses` to limit search operations
   - Use `blocked_domains` to filter unreliable sources
   - Add `user_location` for localized results

2. **CodeExecutionTool:**
   - Keep code simple and focused
   - Provider handles timeouts automatically
   - Sandboxed environment limits available packages

3. **UrlContextTool:**
   - Only works with Google models
   - Provider handles content fetching and parsing
   - Suitable for documentation and article reading

### Error Handling

Model provider tools have built-in error handling:

```python
from upsonic import Agent, Task
from upsonic.tools.builtin_tools import WebSearchTool

web_search = WebSearchTool()

task = Task(
    description="Search for information, handle any errors gracefully",
    tools=[web_search]
)

agent = Agent(model=model, name="Robust Agent")

try:
    result = agent.do(task)
    print(f"Success: {result}")
except Exception as e:
    print(f"Error occurred: {e}")
```

## Troubleshooting

### Common Issues

**"WebSearchTool is not supported with OpenAIChatModel"**
- **Problem**: Using wrong model type
- **Solution**: Use `openai-responses/gpt-4o` instead of `openai/gpt-4o`

**"Unsupported data type" with Azure OpenAI**
- **Problem**: Azure OpenAI doesn't support model provider tools
- **Solution**: Use custom tools or switch to standard OpenAI API

**"UrlContextTool is not supported by OpenAIResponsesModel"**
- **Problem**: UrlContextTool only works with Google
- **Solution**: Switch to Google model (`google/gemini-1.5-pro`)

**Tools not being called by agent**
- **Check**: Verify correct model provider
- **Check**: Ensure tool is properly imported
- **Check**: Review task description for clarity

### Debugging

1. **Enable Debug Mode:**
   ```python
   agent = Agent(model=model, name="Agent", debug=True)
   result = agent.do(task)
   ```

2. **Check Tool Registration:**
   - Tools should appear in execution logs
   - Verify provider compatibility

3. **Test Simple Cases First:**
   ```python
   # Start with basic configuration
   tool = WebSearchTool()
   task = Task(description="Simple search query", tools=[tool])
   ```

4. **Verify Model Configuration:**
   ```python
   # Correct for OpenAI Responses
   model = OpenAIResponsesModel(model_name="gpt-4o", provider="openai")
   
   # Wrong - will not work
   # model = OpenAIChatModel(model_name="gpt-4o")
   ```

## Performance Considerations

### Sequential Execution

Model provider tools always execute sequentially:
- No parallel execution
- Provider manages execution order
- Cannot configure parallel behavior

### Rate Limiting

Rate limiting is provider-managed:
- Automatic rate limit handling
- No configuration needed
- Retries handled by provider

### Caching

Caching is provider-managed:
- Cannot configure framework-level caching
- Provider may cache internally
- No control over cache TTL

### Timeouts

Timeouts are provider-managed:
- No configuration parameter
- Provider sets reasonable defaults
- Automatic timeout handling

## Migration from Custom Tools

If you're using custom tools and want to switch to model provider tools:

**Before (Custom Tool):**
```python
from upsonic.tools import tool

@tool
def web_search(query: str) -> str:
    """Custom web search implementation."""
    # Your implementation
    return results
```

**After (Model Provider Tool):**
```python
from upsonic.tools.builtin_tools import WebSearchTool

# Use provider's native implementation
web_search = WebSearchTool()
```

**Benefits of Migration:**
- Provider-optimized performance
- No maintenance required
- Automatic updates and improvements
- Built-in rate limiting and error handling

**Trade-offs:**
- Less configuration control
- Provider-specific availability
- Sequential execution only
- No custom caching or hooks
